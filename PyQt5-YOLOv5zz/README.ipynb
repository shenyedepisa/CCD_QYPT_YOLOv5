{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 训练\n",
        "在 `yolov5` 文件夹中可以使用写好的脚本 `scripts/train.sh` 进行训练或更改适合的参数进行训练，训练后的模式会存放在 `runs/train/exp{%d}/weights`\n",
        "\n",
        "也可以写入自己的参数进行训练\n",
        "\n",
        "### opt参数详解\n",
        "```\n",
        "weights:加载的权重文件（可以用我们预训练好的 mi.pt 或者 yolo 官方的 yolov5x.pt）\n",
        "cfg:模型配置文件，网络结构\n",
        "data:数据集配置文件，数据集路径，类名等（目前配好的是 yolov5x.yaml）\n",
        "hyp:超参数文件\n",
        "epochs:训练总轮次，默认300\n",
        "batch-size:批次大小，默认32\n",
        "img-size:输入图片分辨率大小，默认 640\n",
        "rect:是否采用矩形训练，默认 False\n",
        "resume:接着打断训练上次的结果接着训练\n",
        "nosave:不保存模型，默认False\n",
        "notest:不进行test，默认False\n",
        "noautoanchor:不自动调整anchor，默认False\n",
        "evolve:是否进行超参数进化，默认False\n",
        "bucket:谷歌云盘bucket\n",
        "cache-images:是否提前缓存图片到内存，以加快训练速度，默认False\n",
        "name:数据集名字，如果设置：results.txt to results_name.txt\n",
        "device:训练的设备，cpu；0(表示一个gpu设备cuda:0)；0,1,2,3(多个gpu设备)\n",
        "multi-scale:是否进行多尺度训练，默认False\n",
        "single-cls:数据集是否只有一个类别，默认False\n",
        "adam:是否使用adam优化器\n",
        "sync-bn:是否使用跨卡同步BN,在DDP模式使用\n",
        "local_rank:gpu编号\n",
        "logdir:存放日志的目录，默认为 'runs/'\n",
        "workers:dataloader 的最大 worker 数量\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 300 --workers 16 --data data/mi.yaml --device 0 --cfg models/yolov5x.yaml --weights weights/yolov5x.pt --single --name origin"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='models/yolov5x.yaml', data='data/mycoco.yaml', device='0', epochs=300, evolve=False, global_rank=-1, hyp='data/hyp.finetune.yaml', img_size=[640, 640], local_rank=-1, logdir='runs/', multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=True, sync_bn=False, total_batch_size=16, weights='weights/mi.pt', workers=16, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/\", view at http://localhost:6006/\n",
            "Hyperparameters {'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mixup': 0.0}\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  1    315680  models.common.BottleneckCSP             [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
            "  9                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   5435520  models.common.BottleneckCSP             [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1   1360960  models.common.BottleneckCSP             [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 407 layers, 8.84337e+07 parameters, 8.84337e+07 gradients\n",
            "\n",
            "Transferred 800/802 items from weights/mi.pt\n",
            "Optimizer groups: 134 .bias, 142 conv.weight, 131 other\n",
            "Scanning labels ../dataset/big_coco/labels/train2017.cache (9626 found, 0 missing, 0 empty, 0 duplicate, for 9626 images): 9626it [00:00, 28585.04it/s]\n",
            "Scanning labels ../dataset/big_coco/labels/train2017.cache (9626 found, 0 missing, 0 empty, 0 duplicate, for 9626 images): 9626it [00:00, 28288.94it/s]\n",
            "\n",
            "Analyzing anchors... anchors/target = 6.12, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 16 dataloader workers\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     0/299     11.1G   0.01673  0.005284         0   0.02201        22       640^C\n",
            "     0/299     11.1G   0.01673  0.005284         0   0.02201        22       640\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 452, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 270, in train\n",
            "    loss, loss_items = compute_loss(pred, targets.to(device), model)  # scaled by batch_size\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 检测\n",
        "脚本中还有 `scripts/detect.sh` 可以检测自己刚训练好的训练模型，就是 `runs/exp{%d}/weights` 看看机器的训练结果\n",
        "\n",
        "也可以写入自己的参数进行检测\n",
        "\n",
        "### opt 参数详解\n",
        "```\n",
        "weights: 测试的模型权重文件（测试文件一般在 runs 里边）\n",
        "data:数据集配置文件，数据集路径，类名等\n",
        "batch-size:前向传播时的批次, 默认32\n",
        "img-size:输入图片分辨率大小, 默认640\n",
        "conf-thres:筛选框的时候的置信度阈值, 默认0.001\n",
        "iou-thres:进行NMS的时候的IOU阈值, 默认0.6\n",
        "save-json:是否按照coco的json格式保存预测框，并且使用cocoapi做评估(需要同样coco的json格式的标签), 默认False\n",
        "task:设置测试形式, 默认val, 若参数为 val 和 test，即直接测试，若为 study 则评估 yolov5 系列和 yolov3-spp 各个模型在各个尺度下的指标并可视化\n",
        "device:测试的设备，cpu；0(表示一个gpu设备cuda:0)；0,1,2,3(多个gpu设备)\n",
        "single-cls:数据集是否只有一个类别，默认False\n",
        "augment:测试时是否使用TTA(test time augmentation), 默认False\n",
        "merge:在进行NMS时，是否通过合并方式获得预测框, 默认False\n",
        "verbose:是否打印出每个类别的mAP, 默认False\n",
        "save-txt:是否以txt文件的形式保存模型预测的框坐标, 默认False\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --device 0 --source ../dataset/c_gray --output ../dataset/testresult --weights runs/exp16/weights/best.pt --conf 0.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.1, device='0', img_size=640, iou_thres=0.5, output='../dataset/testresult', save_txt=False, source='../dataset/c_gray', update=False, view_img=False, weights=['runs/exp16/weights/best.pt'])\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', total_memory=16130MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 284 layers, 8.83906e+07 parameters, 8.45317e+07 gradients\n",
            "image 1/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/a_0038.jpg: 640x512 1 items, Done. (0.037s)\n",
            "image 2/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0000.jpg: 448x640 1 items, Done. (0.034s)\n",
            "image 3/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0001.jpg: 640x384 Done. (0.031s)\n",
            "image 4/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0002.jpg: 640x512 Done. (0.022s)\n",
            "image 5/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0003.jpg: 576x640 1 items, Done. (0.033s)\n",
            "image 6/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0004.jpg: 640x512 1 items, Done. (0.023s)\n",
            "image 7/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0005.jpg: 640x384 1 items, Done. (0.023s)\n",
            "image 8/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0006.jpg: 640x640 1 items, Done. (0.023s)\n",
            "image 9/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0007.jpg: 640x512 3 items, Done. (0.023s)\n",
            "image 10/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0008.jpg: 512x640 1 items, Done. (0.033s)\n",
            "image 11/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0009.jpg: 640x320 Done. (0.034s)\n",
            "image 12/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0010.jpg: 640x512 1 items, Done. (0.024s)\n",
            "image 13/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0011.jpg: 256x640 2 items, Done. (0.034s)\n",
            "image 14/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0012.jpg: 512x640 1 items, Done. (0.024s)\n",
            "image 15/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0013.jpg: 640x512 1 items, Done. (0.024s)\n",
            "image 16/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0014.jpg: 512x640 1 items, Done. (0.024s)\n",
            "image 17/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0015.jpg: 448x640 1 items, Done. (0.024s)\n",
            "image 18/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0016.jpg: 576x640 1 items, Done. (0.023s)\n",
            "image 19/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0017.jpg: 640x384 1 items, Done. (0.024s)\n",
            "image 20/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0018.jpg: 512x640 1 items, Done. (0.024s)\n",
            "image 21/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0019.jpg: 512x640 1 items, Done. (0.027s)\n",
            "image 22/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0020.jpg: 512x640 Done. (0.023s)\n",
            "image 23/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0021.jpg: 640x448 1 items, Done. (0.030s)\n",
            "image 24/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0022.jpg: 384x640 2 items, Done. (0.033s)\n",
            "image 25/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0023.jpg: 640x512 1 items, Done. (0.023s)\n",
            "image 26/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0024.jpg: 640x512 1 items, Done. (0.022s)\n",
            "image 27/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0025.jpg: 640x384 1 items, Done. (0.023s)\n",
            "image 28/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0026.jpg: 640x640 4 items, Done. (0.023s)\n",
            "image 29/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0027.jpg: 512x640 1 items, Done. (0.023s)\n",
            "image 30/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0028.jpg: 512x640 Done. (0.022s)\n",
            "image 31/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0029.jpg: 512x640 1 items, Done. (0.023s)\n",
            "image 32/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0030.jpg: 640x640 1 items, Done. (0.024s)\n",
            "image 33/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0031.jpg: 640x448 2 items, Done. (0.023s)\n",
            "image 34/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0032.jpg: 640x512 2 items, Done. (0.023s)\n",
            "image 35/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0033.jpg: 640x512 1 items, Done. (0.022s)\n",
            "image 36/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0034.jpg: 640x448 Done. (0.021s)\n",
            "image 37/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0035.jpg: 640x384 5 items, Done. (0.022s)\n",
            "image 38/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0036.jpg: 640x512 1 items, Done. (0.023s)\n",
            "image 39/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0037.jpg: 640x512 1 items, Done. (0.022s)\n",
            "image 40/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0038.jpg: 512x640 1 items, Done. (0.023s)\n",
            "image 41/41 /home/jovyan/BY1506125/alvin/yolo/dataset/c_gray/c_0039.jpg: 640x512 1 items, Done. (0.023s)\n",
            "Results saved to ../dataset/testresult\n",
            "Done. (1.711s)\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}